{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e40dd73",
   "metadata": {},
   "source": [
    "# Flip Robo Technologies Web Scraping - Assignment - 4\n",
    "\n",
    "## Solved by Mihir Bhoite - Batch - DS2406"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2764b282",
   "metadata": {},
   "source": [
    "## Question -1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:                     A)Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da0914d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3392579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38538190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "495476a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce50acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d171fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    table = driver.find_element(By.XPATH, '//table[contains(@class,\"wikitable\")]')\n",
    "    rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "except NoSuchElementException:\n",
    "    print(\"Table not found!\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c3b29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    try:\n",
    "        columns = row.find_elements(By.TAG_NAME, 'td')\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].text.strip()\n",
    "        artist = columns[2].text.strip()\n",
    "        upload_date = columns[3].text.strip()\n",
    "        views = columns[4].text.strip()\n",
    "\n",
    "        data.append([ rank, name, artist, views, upload_date ])\n",
    "    except IndexError:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ca8e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Rank  \\\n",
      "0                             \"Baby Shark Dance\"[7]   \n",
      "1                                   \"Despacito\"[10]   \n",
      "2                        \"Johny Johny Yes Papa\"[18]   \n",
      "3                                   \"Bath Song\"[19]   \n",
      "4                           \"Wheels on the Bus\"[20]   \n",
      "5                               \"See You Again\"[21]   \n",
      "6                                \"Shape of You\"[26]   \n",
      "7                 \"Phonics Song with Two Words\"[29]   \n",
      "8                                 \"Uptown Funk\"[30]   \n",
      "9                               \"Gangnam Style\"[31]   \n",
      "10  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[36]   \n",
      "11                                     \"Axel F\"[37]   \n",
      "12                             \"Dame Tu Cosita\"[38]   \n",
      "13   \"Masha and the Bear ‚Äì Recipe for Disaster\"[39]   \n",
      "14                        \"Baa Baa Black Sheep\"[40]   \n",
      "15                             \"Lakdi Ki Kathi\"[41]   \n",
      "16                                      \"Sugar\"[42]   \n",
      "17                             \"Counting Stars\"[43]   \n",
      "18                                       \"Roar\"[44]   \n",
      "19           \"Waka Waka (This Time for Africa)\"[45]   \n",
      "20                      \"Shree Hanuman Chalisa\"[46]   \n",
      "21          \"Humpty the train on a fruits ride\"[47]   \n",
      "22                                      \"Sorry\"[48]   \n",
      "23                          \"Thinking Out Loud\"[49]   \n",
      "24                                    \"Perfect\"[50]   \n",
      "25                                 \"Dark Horse\"[51]   \n",
      "26                                 \"Let Her Go\"[52]   \n",
      "27                                      \"Faded\"[53]   \n",
      "28                             \"Girls Like You\"[54]   \n",
      "29                                    \"Lean On\"[55]   \n",
      "\n",
      "                                                 Name Artist Views  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories  15.12   [A]   \n",
      "1                                          Luis Fonsi   8.55   [B]   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.95         \n",
      "3                          Cocomelon - Nursery Rhymes   6.85         \n",
      "4                          Cocomelon - Nursery Rhymes   6.56         \n",
      "5                                         Wiz Khalifa   6.40   [C]   \n",
      "6                                          Ed Sheeran   6.33   [D]   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs   6.00         \n",
      "8                                         Mark Ronson   5.33         \n",
      "9                                                 Psy   5.30   [E]   \n",
      "10                                        Miroshka TV   5.15         \n",
      "11                                         Crazy Frog   4.78         \n",
      "12                                      Ultra Records   4.74         \n",
      "13                                         Get Movies   4.60         \n",
      "14                         Cocomelon - Nursery Rhymes   4.17         \n",
      "15                                       Jingle Toons   4.13         \n",
      "16                                           Maroon 5   4.09         \n",
      "17                                        OneRepublic   4.05         \n",
      "18                                         Katy Perry   4.03         \n",
      "19                                            Shakira   4.01         \n",
      "20                              T-Series Bhakti Sagar   3.97         \n",
      "21      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.89         \n",
      "22                                      Justin Bieber   3.84         \n",
      "23                                         Ed Sheeran   3.79         \n",
      "24                                         Ed Sheeran   3.78         \n",
      "25                                         Katy Perry   3.77         \n",
      "26                                          Passenger   3.70         \n",
      "27                                        Alan Walker   3.67         \n",
      "28                                           Maroon 5   3.65         \n",
      "29                               Major Lazer Official   3.65         \n",
      "\n",
      "          Upload Date  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4        May 24, 2018  \n",
      "5       April 6, 2015  \n",
      "6    January 30, 2017  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9       July 15, 2012  \n",
      "10  February 27, 2018  \n",
      "11      June 16, 2009  \n",
      "12      April 5, 2018  \n",
      "13   January 31, 2012  \n",
      "14      June 25, 2018  \n",
      "15      June 14, 2018  \n",
      "16   January 14, 2015  \n",
      "17       May 31, 2013  \n",
      "18  September 5, 2013  \n",
      "19       June 4, 2010  \n",
      "20       May 10, 2011  \n",
      "21   January 26, 2018  \n",
      "22   October 22, 2015  \n",
      "23    October 7, 2014  \n",
      "24   November 9, 2017  \n",
      "25  February 20, 2014  \n",
      "26      July 25, 2012  \n",
      "27   December 3, 2015  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "# Step 5: Store the data in a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"Name\", \"Artist\", \"Views\", \"Upload Date\"])\n",
    "\n",
    "# Step 6: Output the data\n",
    "print(df)\n",
    "\n",
    "df.to_csv('most_viewed_youtube_videos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7a30a",
   "metadata": {},
   "source": [
    "## Question 2. Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03e899a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Step 1: Set up the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "# Step 2:\n",
    "time.sleep(5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "981361b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Assuming the link to fixtures is found using a button or a navigation item\n",
    "    fixtures_link = driver.find_element(By.XPATH, \"//a[contains(@href, '/fixtures')]\")  \n",
    "    fixtures_link.click()\n",
    "except NoSuchElementException:\n",
    "    print(\"Fixtures link not found\")\n",
    "    driver.quit()\n",
    "\n",
    "    # Step 3: Wait for the fixtures page to load\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3c76119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on More Matches option for drop down below\n",
    "more_matches_link = driver.find_element(By.XPATH, \"//button[@class='match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3 morematches']\")\n",
    "more_matches_link.click()\n",
    "\n",
    "# Step 4: Scrape the fixtures data (Series, Place, Date, Time)\n",
    "fixtures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a378b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Assuming the fixtures are in a table or listed div structure\n",
    "fixture_items = driver.find_elements(By.XPATH, \"//div[@class='match-card match-card-fw match-card-up match-card-modify ng-scope t20-card']\")  # Adjust this selector based on the website structure\n",
    "for fixture in fixture_items:\n",
    "    try:\n",
    "        series = fixture.find_element(By.XPATH, \".//h5[@class='match-tournament-name ng-binding']\").text\n",
    "        place = fixture.find_element(By.XPATH, \".//div[@class='match-venue ng-scope']\").text\n",
    "        date = fixture.find_element(By.XPATH, \".//div[@class='match-dates ng-binding']\").text\n",
    "        time = fixture.find_element(By.XPATH, \".//div[@class= 'match-time no-margin ng-binding']\").text\n",
    "\n",
    "        fixtures.append([series, place, date, time])\n",
    "    except NoSuchElementException:\n",
    "        print(\"Some fixture details missing, skipping this fixture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1850971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Series  \\\n",
      "0                ICC Womens T20 World Cup 2024   \n",
      "1                ICC Womens T20 World Cup 2024   \n",
      "2     Bangladesh Tour of India T20 Series 2024   \n",
      "3                ICC Womens T20 World Cup 2024   \n",
      "4     Bangladesh Tour of India T20 Series 2024   \n",
      "5     Bangladesh Tour of India T20 Series 2024   \n",
      "6                ICC Womens T20 World Cup 2024   \n",
      "7   India Tour of South Africa T20 Series 2024   \n",
      "8   India Tour of South Africa T20 Series 2024   \n",
      "9   India Tour of South Africa T20 Series 2024   \n",
      "10  India Tour of South Africa T20 Series 2024   \n",
      "\n",
      "                                                Place    Date       Time  \n",
      "0          Dubai International Cricket Stadium, Dubai   4 Oct  19:30 IST  \n",
      "1          Dubai International Cricket Stadium, Dubai   6 Oct  15:30 IST  \n",
      "2   Shrimant Madhavrao Scindia Cricket Stadium, Gw...   6 Oct  19:00 IST  \n",
      "3          Dubai International Cricket Stadium, Dubai   9 Oct  19:30 IST  \n",
      "4                         Arun Jaitley Stadium, Delhi   9 Oct  19:00 IST  \n",
      "5       Rajiv Gandhi International Stadium, Hyderabad  12 Oct  19:00 IST  \n",
      "6                    Sharjah Cricket Stadium, Sharjah  13 Oct  19:30 IST  \n",
      "7                                   Kingsmead, Durban   8 Nov  20:00 IST  \n",
      "8                          St George's Park, Gqeberha  10 Nov  20:00 IST  \n",
      "9                          SuperSport Park, Centurion  13 Nov  20:00 IST  \n",
      "10                The Wanderers Stadium, Johannesburg  15 Nov  20:00 IST  \n"
     ]
    }
   ],
   "source": [
    "# Step 5: Store the data in a pandas DataFrame\n",
    "df = pd.DataFrame(fixtures, columns=[\"Series\", \"Place\", \"Date\", \"Time\"])\n",
    "\n",
    "# Step 6: Output the data\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"team_india_fixtures.csv\", index=False)\n",
    "\n",
    "# Step 7: Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d47b6",
   "metadata": {},
   "source": [
    "# Question - 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2b04b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP(21-22) GSDP(22-23) Share(21-22)  \\\n",
      "0     1                Maharashtra   3,108,022           -       13.17%   \n",
      "1     2                 Tamil Nadu   2,071,286   2,364,514        8.78%   \n",
      "2     3                  Karnataka   1,978,094   2,269,995        8.38%   \n",
      "3     4              Uttar Pradesh   1,975,595   2,258,040        8.37%   \n",
      "4     5                    Gujarat   1,928,683   2,230,609        8.17%   \n",
      "5     6                West Bengal   1,329,238   1,531,758        5.63%   \n",
      "6     7                  Rajasthan   1,193,489   1,365,849        5.06%   \n",
      "7     8             Andhra Pradesh   1,148,471   1,303,524        4.87%   \n",
      "8     9                  Telangana   1,124,204   1,308,034        4.76%   \n",
      "9    10             Madhya Pradesh   1,092,964   1,246,471        4.63%   \n",
      "10   11                     Kerala     934,542   1,046,188        3.96%   \n",
      "11   12                      Delhi     881,336   1,014,688        3.73%   \n",
      "12   13                    Haryana     868,905     984,055        3.68%   \n",
      "13   14                     Odisha     662,886     753,177        2.81%   \n",
      "14   15                      Bihar     650,302     751,396        2.76%   \n",
      "15   16                     Punjab     617,192     676,164        2.62%   \n",
      "16   17                      Assam     411,454     493,167        1.74%   \n",
      "17   18               Chhattisgarh     410,525     464,399        1.74%   \n",
      "18   19                  Jharkhand     358,863     393,722        1.52%   \n",
      "19   20                Uttarakhand     267,143     303,781        1.13%   \n",
      "20   21            Jammu & Kashmir     193,352     224,226        0.82%   \n",
      "21   22           Himachal Pradesh     172,162     191,728        0.73%   \n",
      "22   23                        Goa      84,266      93,672        0.36%   \n",
      "23   24                    Tripura      62,550      72,636        0.27%   \n",
      "24   25                 Chandigarh      46,096      54,285        0.20%   \n",
      "25   26                 Puducherry      43,810      49,643        0.19%   \n",
      "26   27                  Meghalaya      38,785      42,697        0.16%   \n",
      "27   28                     Sikkim      37,557      42,756        0.16%   \n",
      "28   29                    Manipur      36,594           -        0.16%   \n",
      "29   30          Arunachal Pradesh      34,775      39,630        0.15%   \n",
      "30   31                   Nagaland      31,038      35,643        0.13%   \n",
      "31   32                    Mizoram      27,824           -        0.12%   \n",
      "32   33  Andaman & Nicobar Islands      10,371           -        0.04%   \n",
      "33                           India  23,597,399  26,949,646                \n",
      "\n",
      "   GDP ($ billion)  \n",
      "0          414.928  \n",
      "1          276.522  \n",
      "2          264.080  \n",
      "3          263.747  \n",
      "4          257.484  \n",
      "5          177.456  \n",
      "6          159.334  \n",
      "7          153.324  \n",
      "8          150.084  \n",
      "9          145.913  \n",
      "10         124.764  \n",
      "11         117.660  \n",
      "12         116.001  \n",
      "13          88.497  \n",
      "14          86.817  \n",
      "15          82.397  \n",
      "16          54.930  \n",
      "17          54.806  \n",
      "18          47.909  \n",
      "19          35.664  \n",
      "20          25.813  \n",
      "21          22.984  \n",
      "22          11.250  \n",
      "23           8.351  \n",
      "24           6.154  \n",
      "25           5.849  \n",
      "26           5.178  \n",
      "27           5.014  \n",
      "28           4.885  \n",
      "29           4.643  \n",
      "30           4.144  \n",
      "31           3.715  \n",
      "32           1.385  \n",
      "33           3,150  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Step 1: Set up the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://statisticstimes.com/economy/india-statistics.php\")\n",
    "\n",
    "# Step 2: Navigate to the Economy Page\n",
    "try:\n",
    "    india_gdp_link = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    india_gdp_link.click()\n",
    "except NoSuchElementException:\n",
    "    print(\"India GDP link not found\")\n",
    "    driver.quit()\n",
    "\n",
    "# Step 4: Scrape the GDP data\n",
    "time.sleep(3)\n",
    "data = []\n",
    "try:\n",
    "    # Locate the table containing the data\n",
    "    table = driver.find_element(By.XPATH, \"//table[contains(@class,'display dataTable')]\")\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Loop through the table rows and extract data\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(columns) > 0:\n",
    "            rank = columns[0].text.strip()\n",
    "            state = columns[1].text.strip()\n",
    "            gsdp_21_22 = columns[4].text.strip()\n",
    "            gsdp_22_23 = columns[3].text.strip()\n",
    "            share_21_22 = columns[5].text.strip()\n",
    "            gdp_billion_2021 = columns[6].text.strip()\n",
    "\n",
    "            data.append([rank, state, gsdp_21_22, gsdp_22_23, share_21_22, gdp_billion_2021])\n",
    "except NoSuchElementException:\n",
    "    print(\"Table not found\")\n",
    "    driver.quit()\n",
    "\n",
    "# Step 5: Store the data in a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"State\", \"GSDP(21-22)\", \"GSDP(22-23)\", \"Share(21-22)\", \"GDP ($ billion)\"])\n",
    "\n",
    "# Step 6: Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df.to_csv(\"state_gdp_india.csv\", index=False)\n",
    "\n",
    "# Step 7: Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feaa680",
   "metadata": {},
   "source": [
    "# Question-4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b17f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set up the WebDriver\n",
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://github.com/explore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5a5827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Click on the Explore menu and then on the Trending option\n",
    "try:\n",
    "    time.sleep(3)  # Wait for page to load\n",
    "    # Click on the \"Trending\" option \n",
    "    trending_option = driver.find_element(By.XPATH, \"/html/body/div[1]/div[4]/main/div[1]/nav/div/a[3]\")\n",
    "    trending_option.click()\n",
    "\n",
    "except NoSuchElementException:\n",
    "    print(\"Trending option not found\")\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5a9270e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Scrape the trending repositories data\n",
    "time.sleep(3)\n",
    "repositories = []\n",
    "try:\n",
    "    # Locate the trending repositories section\n",
    "    repo_list = driver.find_elements(By.XPATH, \"//article[@class='Box-row']\")\n",
    "\n",
    "    for repo in repo_list:\n",
    "        try:\n",
    "            # Extracting repository title (Owner/Repository)\n",
    "            repo_title = repo.find_element(By.XPATH, \".//h2[@class='h3 lh-condensed']/a\").text.strip()\n",
    "            \n",
    "            # Extracting repository description\n",
    "            try:\n",
    "                repo_description = repo.find_element(By.XPATH, \".//p[@class='col-9 color-fg-muted my-1 pr-4']\").text.strip()\n",
    "            except NoSuchElementException:\n",
    "                repo_description = \"No description available\"\n",
    "            \n",
    "            # Extracting contributors count\n",
    "            try:\n",
    "                contributors_count = repo.find_element(By.XPATH, \".//a[contains(@href, '/graphs/contributors')]\").text.strip()\n",
    "            except NoSuchElementException:\n",
    "                contributors_count = \"No contributors data\"\n",
    "            \n",
    "            # Extracting programming language\n",
    "            try:\n",
    "                language = repo.find_element(By.XPATH, \".//span[@itemprop='programmingLanguage']\").text.strip()\n",
    "            except NoSuchElementException:\n",
    "                language = \"No language specified\"\n",
    "            \n",
    "            # Append the data to the list\n",
    "            repositories.append([repo_title, repo_description, contributors_count, language])\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            continue\n",
    "\n",
    "except NoSuchElementException:\n",
    "    print(\"No repositories found on the page\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b66fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Repository Title  \\\n",
      "0                XengShi / materialYouNewTab   \n",
      "1                   Pythagora-io / gpt-pilot   \n",
      "2                     mediar-ai / screenpipe   \n",
      "3                simplex-chat / simplex-chat   \n",
      "4                            mandiant / capa   \n",
      "5                freeCodeCamp / freeCodeCamp   \n",
      "6                        shardeum / shardeum   \n",
      "7                      dolphin-emu / dolphin   \n",
      "8   EbookFoundation / free-programming-books   \n",
      "9                       xenova / whisper-web   \n",
      "10                   OpenBB-finance / OpenBB   \n",
      "11                            Avaiga / taipy   \n",
      "12                              grafana / k6   \n",
      "13                              pytorch / ao   \n",
      "14                LadybirdBrowser / ladybird   \n",
      "15              Asabeneh / 30-Days-Of-Python   \n",
      "16                           armbian / build   \n",
      "17        dair-ai / Prompt-Engineering-Guide   \n",
      "\n",
      "                               Repository Description    Contributors Count  \\\n",
      "0   A Simple New Tab ( browsers's home page ) insp...  No contributors data   \n",
      "1                         The first real AI developer  No contributors data   \n",
      "2   24/7 local AI screen & mic recording. Build AI...  No contributors data   \n",
      "3   SimpleX - the first messaging network operatin...  No contributors data   \n",
      "4   The FLARE team's open-source tool to identify ...  No contributors data   \n",
      "5   freeCodeCamp.org's open-source codebase and cu...  No contributors data   \n",
      "6     Shardeum is an EVM based autoscaling blockchain  No contributors data   \n",
      "7   Dolphin is a GameCube / Wii emulator, allowing...  No contributors data   \n",
      "8                üìö Freely available programming books  No contributors data   \n",
      "9   ML-powered speech recognition directly in your...  No contributors data   \n",
      "10      Investment Research for Everyone, Everywhere.  No contributors data   \n",
      "11  Turns Data and AI algorithms into production-r...  No contributors data   \n",
      "12  A modern load testing tool, using Go and JavaS...  No contributors data   \n",
      "13  PyTorch native quantization and sparsity for t...  No contributors data   \n",
      "14                      Truly independent web browser  No contributors data   \n",
      "15  30 days of Python programming challenge is a s...  No contributors data   \n",
      "16  Armbian Linux build framework generates custom...  No contributors data   \n",
      "17  üêô Guides, papers, lecture, notebooks and resou...  No contributors data   \n",
      "\n",
      "                 Language  \n",
      "0                    HTML  \n",
      "1                  Python  \n",
      "2                    Rust  \n",
      "3                 Haskell  \n",
      "4                  Python  \n",
      "5              TypeScript  \n",
      "6              TypeScript  \n",
      "7                     C++  \n",
      "8   No language specified  \n",
      "9              TypeScript  \n",
      "10                 Python  \n",
      "11                 Python  \n",
      "12                     Go  \n",
      "13                 Python  \n",
      "14                    C++  \n",
      "15                 Python  \n",
      "16                  Shell  \n",
      "17                    MDX  \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Store the data in a pandas DataFrame\n",
    "df = pd.DataFrame(repositories, columns=[\"Repository Title\", \"Repository Description\", \"Contributors Count\", \"Language\"])\n",
    "\n",
    "# Step 5: Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"trending_github_repositories.csv\", index=False)\n",
    "\n",
    "# Step 6: Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f609be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7b7361",
   "metadata": {},
   "source": [
    "# Flip Robo Technologies Assignment - Web Scraping - Selenium\n",
    "\n",
    "## Solved by Mihir Bhoite Batch - DS2406"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c1f8a3",
   "metadata": {},
   "source": [
    "Q1: In this question you have to scrape data using the filters available on the webpage You have to use the location and\n",
    "salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219f938d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.23.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0fb0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver (make sure you have the correct version of chromedriver)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Step 1: Open the Naukri website\n",
    "driver.get('https://www.naukri.com/')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Step 2: Enter \"Data Scientist\" in \"Skill, Designations, and Companies\" field.\n",
    "search_box = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//input[@placeholder='Enter skills / designations / companies']\"))\n",
    ")\n",
    "search_box.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Step 3: Click the search button\n",
    "search_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div[7]/div/div/div[6]\"))\n",
    ")\n",
    "search_button.click()\n",
    "\n",
    "# Step 4: Apply the location filter (Delhi/NCR) and salary filter (3-6 Lakhs)\n",
    "# Wait for filters to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Apply Location Filter\n",
    "location_filter = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//label[@for='chk-Delhi / NCR-cityTypeGid-']\"))\n",
    ")\n",
    "location_filter.click()\n",
    "\n",
    "# Wait for the filter to apply\n",
    "time.sleep(6)\n",
    "\n",
    "# Apply Salary Filter (3-6 Lakhs)\n",
    "salary_filter = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//label[@for='chk-3-6 Lakhs-ctcFilter-']\"))\n",
    ")\n",
    "salary_filter.click()\n",
    "\n",
    "# Wait for the page to reload after applying filters\n",
    "time.sleep(5)\n",
    "\n",
    "job_title=[]\n",
    "job_loc=[]\n",
    "comp_name=[]\n",
    "job_exp=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fb02f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b09e8a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "500e50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_loc.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc781c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c20e37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    comp=i.text\n",
    "    comp_name.append(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1fa084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a68c4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    expe=i.text\n",
    "    job_exp.append(expe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb5ba453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "578a8477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_loc),len(comp_name),len(job_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14720f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
